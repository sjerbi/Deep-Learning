{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 style=\"text-align:center\">Deep Learning  Lab Session </h1>\n",
    "<h1 style=\"text-align:center\">First Lab Session - 3 Hours </h1>\n",
    "<h1 style=\"text-align:center\">Artificial Neural Networks for Handwritten Digits Recognition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Student 1:</b> Sofiene JERBI\n",
    " \n",
    " \n",
    "The aim of this session is to practice with Artificial Neural Networks. Answers and experiments should be made by groups of one or two students. Each group should fill and run appropriate notebook cells. \n",
    "\n",
    "To generate your final report, use print as PDF (Ctrl+P). Do not forget to run all your cells before generating your final report and do not forget to include the names of all participants in the group. The lab session should be completed by April 7th 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "In this session, your will implement, train and test a Neural Network\n",
    "for the Handwritten Digits Recognition problem <a href=\"http://yann.lecun.com/exdb/mnist/\"> [1] </a> with  different settings of hyper parameters. You will use the MNIST dataset which was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). Images of digits were taken from a variety of scanned documents, normalized in size and centered. \n",
    "\n",
    "\n",
    "<img src=\"Nimages/mnist.png\",width=\"350\" height=\"500\" align=\"center\">\n",
    "<center><span>Figure 1: MNIST digits examples</span></center>\n",
    "\n",
    "\n",
    "This assignment includes a written part of programms to help you understand how to build and train\n",
    "your neural net and then to test your code and get restults. \n",
    "\n",
    "1. <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> \n",
    "2. <a href=\"transfer_functions.py\"> transfer_functions.py </a> \n",
    "3.  <a href=\"utils.py \"> utils.py </a> \n",
    "\n",
    "\n",
    "Functions defined inside the python files mentionned above can be imported  using the python command : \n",
    "from filename import *\n",
    "\n",
    "You will use the following libraries:\n",
    "\n",
    "1. <a href=\"http://cs231n.github.io/python-numpy-tutorial/\"> numpy </a>: for creating arrays and using methods to manipulate arrays.\n",
    "\n",
    "2. <a href=\"http://matplotlib.org/\"> matplotlib  </a>: for making plots\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 :  My First Neural Network\n",
    "\n",
    "<b>Part 1</b>: Before designing and writing your code, you will first work on a neural network by hand. \n",
    "Consider the above Neural network with two inputs $X=(x1,x2)$, one hidden layers and a single output unit $(y)$.\n",
    "The initial weights are set to random values. Neurons 6 and 7 represent the bias. Bias values are equal to 1.  \n",
    "Training sample, X = (0.8, 0.2), whose class label is Y=0.4.\n",
    "\n",
    "Assume that the neurons have a Sigmoid activation function  $f(x)=\\frac{1}{(1+e^{-x})}$ and the learning rate $\\mu$=1\n",
    "\n",
    "\n",
    "<img src=\"Nimages/NN.png\", width=\"700\" height=\"900\"> \n",
    "<center><span>Figure 2: Neural network </span></center>\n",
    "\n",
    "\n",
    "<b>Question 1.1.1</b>: Compute the new values of weights $w_{i,j}$ after a forward pass and a backward pass.\n",
    "$w_{i,j}$ is the weight of the connexion between neuron $i$ and neuron $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here :\n",
    "\n",
    "$w_{1,3}=  0.3043226543221547 $ \n",
    "\n",
    "$w_{1,4}=  -0.502734731018754 $\n",
    "\n",
    "$w_{2,3}= 0.8010806635805388 $\n",
    "\n",
    "$w_{2,4}= 0.19931631724531151 $\n",
    "\n",
    "$w_{6,3}= 0.2054033179026934 $\n",
    "\n",
    "$w_{6,4}= -0.40341841377344245 $\n",
    "\n",
    "$w_{3,5}= -0.625414675062796 $\n",
    "\n",
    "$w_{4,5}= 0.38745727217772574 $\n",
    "\n",
    "$w_{7,5}= 0.4606374555351928 $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Neural Network Implementation\n",
    "\n",
    "Please read all source files carefully and understand the data structures and all functions.\n",
    "You are to complete the missing code. \n",
    "First you should define the neural network (using the NeuralNetwork class, see in the <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> file) and reinitialise weights. \n",
    "Then you will to complete the Feed Forward and the Back-propagation functions. \n",
    "\n",
    "<b>Question 1.2.1</b>: Define the neural network corresponding to the one in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from NeuralNetwork import *\n",
    "#create the network\n",
    "my_first_net = NeuralNetwork(2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3 -0.5]\n",
      " [ 0.8  0.2]\n",
      " [ 0.2 -0.4]]\n",
      "[[-0.6]\n",
      " [ 0.4]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#Data preparation \n",
    "X=[0.8,0.2]\n",
    "Y=[0.4]\n",
    "data=[]\n",
    "data.append(X)\n",
    "data.append(Y)\n",
    "\n",
    "#initialize weights\n",
    "wi=np.array([[0.3,-0.5],[0.8,0.2],[0.2,-0.4]])\n",
    "wo=np.array([[-0.6],[0.4],[0.5]])\n",
    "my_first_net.weights_initialisation(wi,wo)\n",
    "print(my_first_net.W_input_to_hidden)\n",
    "print(my_first_net.W_hidden_to_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.2</b>: Implement the Feed Forward function (feedForward(X) in the NeuralNetwork.py file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implement it in the NeuralNetwork.py file and when finalised copy and paste your FeedForward function here\n",
    "\n",
    "    def feedForward(self, inputs):\n",
    "        \n",
    "        self.W_input_to_hidden = np.matrix(self.W_input_to_hidden)\n",
    "        self.W_hidden_to_output = np.matrix(self.W_hidden_to_output)\n",
    "\n",
    "        inputs = np.append(inputs,[1])\n",
    "        self.a_input = np.matrix(inputs)\n",
    "        # Compute input activations\n",
    "        activation_first = self.a_input*self.W_input_to_hidden\n",
    "        \n",
    "        #Compute  hidden activations\n",
    "        output_hidden = self.transfer_function(activation_first)\n",
    "        output_hidden = np.concatenate((output_hidden,np.matrix([1])), axis=1)\n",
    "        self.a_hidden = output_hidden\n",
    "        activation_hidden = output_hidden*self.W_hidden_to_output\n",
    "\n",
    "        \n",
    "        # Compute output activations\n",
    "        output_last = self.transfer_function(activation_hidden)\n",
    "        self.a_out = output_last\n",
    "        return(output_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check your network outputs the expected value (the one you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output activation =0.560\n"
     ]
    }
   ],
   "source": [
    "#test my  Feed Forward function\n",
    "Output_activation=my_first_net.feedForward(X)\n",
    "print(\"output activation =%.3f\" %(Output_activation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.3</b>: Implement the Back-propagation Algorithm (backPropagate(Y) in the NeuralNetwork.py file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implement it in the NeuralNetwork.py file and when finalised copy and paste your BackPropagation function here\n",
    "\n",
    "    def backPropagate(self, targets):\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        targets = np.matrix(targets)\n",
    "        error_last = self.a_out - targets\n",
    "        error_output = np.multiply(error_last,self.dtransfer_function(self.a_out))\n",
    "        # calculate error terms for hidden\n",
    "        error_hidden = np.multiply((self.W_hidden_to_output*error_output.T).T,self.dtransfer_function(self.a_hidden))\n",
    "        error_hidden = np.matrix(np.array(error_hidden)[0][:-1])\n",
    "        \n",
    "        # update output weights\n",
    "        self.W_hidden_to_output=self.W_hidden_to_output-self.learning_rate*self.a_hidden.T*error_output\n",
    "        # update input weights\n",
    "        self.W_input_to_hidden=self.W_input_to_hidden-self.learning_rate*self.a_input.T*error_hidden\n",
    "        # calculate error\n",
    "        error=0.5*np.dot(np.transpose(error_last),error_last)\n",
    "        return(np.array(error)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check the gradient values and weight updates are correct (similar to the ones you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0127567724159\n",
      "wi_new= [[ 0.30432265 -0.50273473]\n",
      " [ 0.80108066  0.19931632]\n",
      " [ 0.20540332 -0.40341841]]\n",
      "wo_new= [[-0.62541468]\n",
      " [ 0.38745727]\n",
      " [ 0.46063746]]\n"
     ]
    }
   ],
   "source": [
    "#test my  Back-propagation function\n",
    "print(my_first_net.backPropagate(Y))\n",
    "#Print weights after backpropagation\n",
    "print('wi_new=', my_first_net.W_input_to_hidden)\n",
    "print('wo_new=', my_first_net.W_hidden_to_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Your Feed Forward and Back-Propagation implementations are working, Great!! Let's tackle a real world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2 : The MNIST Challenge! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Data Preparation</b>\n",
    "\n",
    "The MNIST dataset consists of handwritten digit images it contains 60,000 examples for the training set and 10,000 examples for testing. In this Lab Session, the official training set of 60,000 is divided into an actual training set of 50,000 examples, 10,000 validation examples and 10,000 examples for test. All digit images have been size-normalized and centered in a fixed size image of 28 x 28 pixels. The images are stored in byte form you will use the NumPy python library to read the data files into NumPy arrays that we will use to train the ANN.\n",
    "\n",
    "The MNIST dataset is available in the Data folder.\n",
    "To get the training, testing and validation data, run the the load_data() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data .....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "training_data, validation_data, test_data=load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>MNIST Dataset Digits Visualisation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ROW = 2\n",
    "COLUMN = 4\n",
    "for i in range(ROW * COLUMN):\n",
    "    # train[i][0] is i-th image data with size 28x28\n",
    "    image = training_data[i][0].reshape(28, 28)   \n",
    "    plt.subplot(ROW, COLUMN, i+1)          \n",
    "    plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n",
    "plt.axis('off')  # do not show axis value\n",
    "plt.tight_layout()   # automatic padding between subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 1</b>: Creating the Neural Networks\n",
    "\n",
    "The input layer of the neural network contains neurons encoding the values of the input pixels. The training data for the network will consist of many 28 by 28 pixel images of scanned handwritten digits, and so the input layer contains 784=28×28 neurons. The second layer of the network is a hidden layer, we set the neuron number in the hidden layer to 30. The output layer contains 10 neurons. \n",
    "\n",
    "<b>Question 2.1.1</b>: Create the network described above using the NeuralNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "my_mnist_net = NeuralNetwork(784,30,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.2</b>: Add the information about the performance of the neural network on the test set at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Accuracy  10.09\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=my_mnist_net.predict(test_data)/100\n",
    "print('Test_Accuracy  %-2.2f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.3</b>: Train the Neural Network and comment your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0049224890  -Training_Accuracy:  92.68  -Test_Accuracy  93.17  -time: 35.51 \n",
      "Iteration:  2/50[==============] -Error: 0.0036308157  -Training_Accuracy:  93.23  -Test_Accuracy  93.52  -time: 72.30 \n",
      "Iteration:  3/50[==============] -Error: 0.0032127118  -Training_Accuracy:  93.79  -Test_Accuracy  93.84  -time: 118.13 \n",
      "Iteration:  4/50[==============] -Error: 0.0032649315  -Training_Accuracy:  94.96  -Test_Accuracy  94.96  -time: 156.89 \n",
      "Iteration:  5/50[==============] -Error: 0.0030176890  -Training_Accuracy:  94.63  -Test_Accuracy  94.40  -time: 193.11 \n",
      "Iteration:  6/50[==============] -Error: 0.0029322946  -Training_Accuracy:  95.12  -Test_Accuracy  94.77  -time: 228.64 \n",
      "Iteration:  7/50[==============] -Error: 0.0029148359  -Training_Accuracy:  95.28  -Test_Accuracy  94.79  -time: 264.00 \n",
      "Iteration:  8/50[==============] -Error: 0.0026389262  -Training_Accuracy:  94.55  -Test_Accuracy  94.11  -time: 302.17 \n",
      "Iteration:  9/50[==============] -Error: 0.0027354834  -Training_Accuracy:  94.50  -Test_Accuracy  94.00  -time: 340.92 \n",
      "Iteration: 10/50[==============] -Error: 0.0026609065  -Training_Accuracy:  95.74  -Test_Accuracy  94.98  -time: 375.43 \n",
      "Iteration: 11/50[==============] -Error: 0.0025724054  -Training_Accuracy:  95.44  -Test_Accuracy  94.87  -time: 411.20 \n",
      "Iteration: 12/50[==============] -Error: 0.0025973531  -Training_Accuracy:  95.84  -Test_Accuracy  95.14  -time: 450.63 \n",
      "Iteration: 13/50[==============] -Error: 0.0024468296  -Training_Accuracy:  95.55  -Test_Accuracy  94.78  -time: 503.14 \n",
      "Iteration: 14/50[==============] -Error: 0.0024335133  -Training_Accuracy:  95.95  -Test_Accuracy  94.98  -time: 555.08 \n",
      "Iteration: 15/50[==============] -Error: 0.0025579287  -Training_Accuracy:  95.89  -Test_Accuracy  95.11  -time: 590.46 \n",
      "Iteration: 16/50[==============] -Error: 0.0024599395  -Training_Accuracy:  96.04  -Test_Accuracy  95.33  -time: 625.94 \n",
      "Iteration: 17/50[==============] -Error: 0.0025623471  -Training_Accuracy:  96.18  -Test_Accuracy  95.33  -time: 663.75 \n",
      "Iteration: 18/50[==============] -Error: 0.0025745927  -Training_Accuracy:  96.09  -Test_Accuracy  95.27  -time: 710.72 \n",
      "Iteration: 19/50[==============] -Error: 0.0023724896  -Training_Accuracy:  95.66  -Test_Accuracy  95.22  -time: 748.97 \n",
      "Iteration: 20/50[==============] -Error: 0.0023901539  -Training_Accuracy:  96.16  -Test_Accuracy  95.12  -time: 789.42 \n",
      "Iteration: 21/50[==============] -Error: 0.0022754448  -Training_Accuracy:  96.19  -Test_Accuracy  95.09  -time: 825.50 \n",
      "Iteration: 22/50[==============] -Error: 0.0025827828  -Training_Accuracy:  96.10  -Test_Accuracy  95.09  -time: 869.47 \n",
      "Iteration: 23/50[==============] -Error: 0.0023266914  -Training_Accuracy:  96.33  -Test_Accuracy  95.26  -time: 909.99 \n",
      "Iteration: 24/50[==============] -Error: 0.0022675597  -Training_Accuracy:  96.51  -Test_Accuracy  95.41  -time: 945.16 \n",
      "Iteration: 25/50[==============] -Error: 0.0022981867  -Training_Accuracy:  96.04  -Test_Accuracy  95.10  -time: 983.51 \n",
      "Iteration: 26/50[==============] -Error: 0.0021772007  -Training_Accuracy:  96.19  -Test_Accuracy  95.21  -time: 1016.97 \n",
      "Iteration: 27/50[==============] -Error: 0.0022974451  -Training_Accuracy:  96.51  -Test_Accuracy  95.47  -time: 1060.53 \n",
      "Iteration: 28/50[==============] -Error: 0.0021633535  -Training_Accuracy:  96.43  -Test_Accuracy  95.40  -time: 1097.54 \n",
      "Iteration: 29/50[==============] -Error: 0.0021525240  -Training_Accuracy:  96.53  -Test_Accuracy  95.41  -time: 1145.47 \n",
      "Iteration: 30/50[==============] -Error: 0.0020505871  -Training_Accuracy:  96.91  -Test_Accuracy  95.48  -time: 1183.04 \n",
      "Iteration: 31/50[==============] -Error: 0.0020734503  -Training_Accuracy:  96.35  -Test_Accuracy  94.88  -time: 1218.61 \n",
      "Iteration: 32/50[==============] -Error: 0.0021124430  -Training_Accuracy:  96.43  -Test_Accuracy  95.20  -time: 1256.57 \n",
      "Iteration: 33/50[==============] -Error: 0.0021081625  -Training_Accuracy:  96.69  -Test_Accuracy  95.42  -time: 1294.39 \n",
      "Iteration: 34/50[==============] -Error: 0.0021227096  -Training_Accuracy:  96.75  -Test_Accuracy  95.26  -time: 1327.51 \n",
      "Iteration: 35/50[==============] -Error: 0.0021215657  -Training_Accuracy:  96.29  -Test_Accuracy  95.20  -time: 1362.03 \n",
      "Iteration: 36/50[==============] -Error: 0.0020892224  -Training_Accuracy:  96.75  -Test_Accuracy  95.40  -time: 1402.31 \n",
      "Iteration: 37/50[==============] -Error: 0.0019544426  -Training_Accuracy:  97.05  -Test_Accuracy  95.41  -time: 1438.63 \n",
      "Iteration: 38/50[==============] -Error: 0.0019590973  -Training_Accuracy:  97.04  -Test_Accuracy  95.24  -time: 1472.75 \n",
      "Iteration: 39/50[==============] -Error: 0.0019995781  -Training_Accuracy:  97.00  -Test_Accuracy  95.53  -time: 1505.58 \n",
      "Iteration: 40/50[==============] -Error: 0.0021097917  -Training_Accuracy:  96.78  -Test_Accuracy  95.21  -time: 1541.24 \n",
      "Iteration: 41/50[==============] -Error: 0.0020381247  -Training_Accuracy:  97.09  -Test_Accuracy  95.45  -time: 1579.09 \n",
      "Iteration: 42/50[==============] -Error: 0.0018558581  -Training_Accuracy:  96.85  -Test_Accuracy  95.49  -time: 1617.77 \n",
      "Iteration: 43/50[==============] -Error: 0.0018025198  -Training_Accuracy:  96.84  -Test_Accuracy  95.21  -time: 1655.65 \n",
      "Iteration: 44/50[==============] -Error: 0.0020181205  -Training_Accuracy:  97.16  -Test_Accuracy  95.64  -time: 1685.17 \n",
      "Iteration: 45/50[==============] -Error: 0.0019172317  -Training_Accuracy:  96.87  -Test_Accuracy  95.35  -time: 1716.16 \n",
      "Iteration: 46/50[==============] -Error: 0.0018285560  -Training_Accuracy:  97.01  -Test_Accuracy  95.45  -time: 1745.76 \n",
      "Iteration: 47/50[==============] -Error: 0.0019470687  -Training_Accuracy:  96.95  -Test_Accuracy  95.27  -time: 1775.23 \n",
      "Iteration: 48/50[==============] -Error: 0.0019699107  -Training_Accuracy:  96.88  -Test_Accuracy  95.52  -time: 1804.91 \n",
      "Iteration: 49/50[==============] -Error: 0.0018310100  -Training_Accuracy:  96.92  -Test_Accuracy  95.45  -time: 1834.78 \n",
      "Iteration: 50/50[==============] -Error: 0.0017575066  -Training_Accuracy:  97.21  -Test_Accuracy  95.72  -time: 1864.47 \n"
     ]
    }
   ],
   "source": [
    "#train your network \n",
    "my_mnist_net.train(training_data,validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save your model in Models/ using a distinguishing name for your model (architecture, learning rate, etc...)\n",
    "my_mnist_net.save(\"Models/model_1-iterations_50-learning_1-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Figures/model1.png\", width=\"700\" height=\"900\"> \n",
    "<img src=\"Figures/model1_1.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We fing that the training accuracy is from the beginning very high (92.22%) and that it improves in a O(1/n) way to achieve a very good final result of 96.57%. We can notice that the training doesn't go on the best way at each step (the model regresses). This may be because of a learning rate \"too high\" making the the weights change of big steps between each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "my_mnist_net.load(\"Models/model_1-iterations_50-learning_1-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.4</b>: Guess digit, Implement and test a python function that predict the class of a digit (the folder images_test contains some examples of images of digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    if len(rgb.shape)==3:\n",
    "        gray = np.dot(rgb[...,:3], [0.299, 0.587, 0.114])/np.amax(rgb)\n",
    "        if gray[0][0]>0.5:\n",
    "            return 1-gray\n",
    "        else:\n",
    "            return gray\n",
    "    else:\n",
    "        gray = rgb/np.amax(rgb)\n",
    "        if gray[0][0]>0.5:\n",
    "            return 1-gray\n",
    "        else:\n",
    "            return gray\n",
    "\n",
    "def guess(self, filename):\n",
    "    filename='Images_test/'+filename\n",
    "    img = np.array(ImageEnhance.Contrast(Image.open(filename)).enhance(5).resize((28,28),Image.ANTIALIAS))\n",
    "    input = rgb2gray(img).flatten()\n",
    "    plt.imshow(input.reshape(28,28), cmap='gray')\n",
    "    plt.show()\n",
    "    prediction = np.argmax(self.feedForward(input))\n",
    "    return(prediction)\n",
    "\n",
    "def guess_list(self, filenames):\n",
    "    predictions=[]\n",
    "    for filename in filenames:\n",
    "        filename='Images_test/'+filename\n",
    "        img = np.array(ImageEnhance.Contrast(Image.open(filename)).enhance(1).resize((28,28),Image.ANTIALIAS))\n",
    "        input = rgb2gray(img).flatten()\n",
    "        plt.imshow(input.reshape(28,28), cmap='gray')\n",
    "        plt.show()\n",
    "        prediction = np.argmax(self.feedForward(input))\n",
    "        predictions+=[(filename[12],prediction)]\n",
    "    return(predictions)\n",
    "\n",
    "print(guess(my_mnist_net,'9.bmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The implemetation above uses a new library (PIL) to read images, enhance a little bit their contrast and resize them to the 28x28 format. Then we convert them into numpy arrays, do an rgb->gray transform if that's necessary, and impose a black background because that's the way the way the images are encoded in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 4), ('5', 5), ('9', 9), ('2', 2), ('3', 3), ('7', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(guess_list(my_mnist_net,['4.bmp','5.bmp','9.bmp','2.png','3.png','7.png']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We see that the implementation works pretty well even with new images that we added to the test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Change the neural network structure and parameters to optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.1</b>: Change the learning rate (0.001, 0.1, 1.0 , 10). Train the new neural nets with the original specifications (Part 2.1), for 50 iterations. \n",
    "Plot test accuracy vs iteration for each learning rate on the same graph. Report the maximum\n",
    "test accuracy achieved for each learning rate. Which one achieves the maximum test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0517632607  -Training_Accuracy:  15.10  -Test_Accuracy  14.30  -time: 32.52 \n",
      "Iteration:  2/50[==============] -Error: 0.0431824423  -Training_Accuracy:  21.05  -Test_Accuracy  20.59  -time: 66.06 \n",
      "Iteration:  3/50[==============] -Error: 0.0397219773  -Training_Accuracy:  27.06  -Test_Accuracy  26.75  -time: 99.96 \n",
      "Iteration:  4/50[==============] -Error: 0.0314823737  -Training_Accuracy:  33.48  -Test_Accuracy  33.80  -time: 133.55 \n",
      "Iteration:  5/50[==============] -Error: 0.0217326013  -Training_Accuracy:  48.94  -Test_Accuracy  49.50  -time: 168.24 \n",
      "Iteration:  6/50[==============] -Error: 0.0155610351  -Training_Accuracy:  59.44  -Test_Accuracy  60.58  -time: 202.72 \n",
      "Iteration:  7/50[==============] -Error: 0.0122707563  -Training_Accuracy:  65.74  -Test_Accuracy  66.82  -time: 235.41 \n",
      "Iteration:  8/50[==============] -Error: 0.0104986977  -Training_Accuracy:  71.97  -Test_Accuracy  73.78  -time: 268.41 \n",
      "Iteration:  9/50[==============] -Error: 0.0094389097  -Training_Accuracy:  77.15  -Test_Accuracy  78.92  -time: 301.56 \n",
      "Iteration: 10/50[==============] -Error: 0.0086689096  -Training_Accuracy:  81.09  -Test_Accuracy  82.91  -time: 335.62 \n",
      "Iteration: 11/50[==============] -Error: 0.0080493368  -Training_Accuracy:  83.67  -Test_Accuracy  85.41  -time: 369.20 \n",
      "Iteration: 12/50[==============] -Error: 0.0075672697  -Training_Accuracy:  85.54  -Test_Accuracy  87.22  -time: 401.83 \n",
      "Iteration: 13/50[==============] -Error: 0.0071567385  -Training_Accuracy:  86.81  -Test_Accuracy  88.30  -time: 435.79 \n",
      "Iteration: 14/50[==============] -Error: 0.0068043803  -Training_Accuracy:  87.68  -Test_Accuracy  89.09  -time: 469.08 \n",
      "Iteration: 15/50[==============] -Error: 0.0064960556  -Training_Accuracy:  88.31  -Test_Accuracy  89.65  -time: 500.36 \n",
      "Iteration: 16/50[==============] -Error: 0.0062111318  -Training_Accuracy:  88.58  -Test_Accuracy  89.91  -time: 533.14 \n",
      "Iteration: 17/50[==============] -Error: 0.0059632930  -Training_Accuracy:  88.91  -Test_Accuracy  90.07  -time: 566.49 \n",
      "Iteration: 18/50[==============] -Error: 0.0057351269  -Training_Accuracy:  89.15  -Test_Accuracy  90.25  -time: 600.06 \n",
      "Iteration: 19/50[==============] -Error: 0.0055364592  -Training_Accuracy:  89.30  -Test_Accuracy  90.43  -time: 634.11 \n",
      "Iteration: 20/50[==============] -Error: 0.0053559363  -Training_Accuracy:  89.55  -Test_Accuracy  90.69  -time: 666.40 \n",
      "Iteration: 21/50[==============] -Error: 0.0051974126  -Training_Accuracy:  89.69  -Test_Accuracy  90.83  -time: 698.72 \n",
      "Iteration: 22/50[==============] -Error: 0.0050520316  -Training_Accuracy:  89.89  -Test_Accuracy  90.89  -time: 733.15 \n",
      "Iteration: 23/50[==============] -Error: 0.0049195336  -Training_Accuracy:  90.01  -Test_Accuracy  91.03  -time: 766.08 \n",
      "Iteration: 24/50[==============] -Error: 0.0048063365  -Training_Accuracy:  90.18  -Test_Accuracy  91.27  -time: 798.63 \n",
      "Iteration: 25/50[==============] -Error: 0.0046993489  -Training_Accuracy:  90.30  -Test_Accuracy  91.29  -time: 830.90 \n",
      "Iteration: 26/50[==============] -Error: 0.0045992597  -Training_Accuracy:  90.42  -Test_Accuracy  91.44  -time: 862.07 \n",
      "Iteration: 27/50[==============] -Error: 0.0045023513  -Training_Accuracy:  90.51  -Test_Accuracy  91.58  -time: 893.19 \n",
      "Iteration: 28/50[==============] -Error: 0.0044225285  -Training_Accuracy:  90.65  -Test_Accuracy  91.66  -time: 924.25 \n",
      "Iteration: 29/50[==============] -Error: 0.0043480527  -Training_Accuracy:  90.74  -Test_Accuracy  91.68  -time: 955.27 \n",
      "Iteration: 30/50[==============] -Error: 0.0042731143  -Training_Accuracy:  90.81  -Test_Accuracy  91.75  -time: 986.55 \n",
      "Iteration: 31/50[==============] -Error: 0.0042054008  -Training_Accuracy:  90.96  -Test_Accuracy  91.88  -time: 1018.26 \n",
      "Iteration: 32/50[==============] -Error: 0.0041494375  -Training_Accuracy:  91.01  -Test_Accuracy  92.00  -time: 1049.54 \n",
      "Iteration: 33/50[==============] -Error: 0.0040890167  -Training_Accuracy:  91.10  -Test_Accuracy  92.06  -time: 1080.75 \n",
      "Iteration: 34/50[==============] -Error: 0.0040311259  -Training_Accuracy:  91.18  -Test_Accuracy  92.11  -time: 1113.69 \n",
      "Iteration: 35/50[==============] -Error: 0.0039798039  -Training_Accuracy:  91.23  -Test_Accuracy  92.14  -time: 1146.19 \n",
      "Iteration: 36/50[==============] -Error: 0.0039339280  -Training_Accuracy:  91.27  -Test_Accuracy  92.16  -time: 1177.35 \n",
      "Iteration: 37/50[==============] -Error: 0.0038873763  -Training_Accuracy:  91.36  -Test_Accuracy  92.30  -time: 1209.17 \n",
      "Iteration: 38/50[==============] -Error: 0.0038438349  -Training_Accuracy:  91.48  -Test_Accuracy  92.37  -time: 1240.24 \n",
      "Iteration: 39/50[==============] -Error: 0.0038027556  -Training_Accuracy:  91.52  -Test_Accuracy  92.37  -time: 1271.25 \n",
      "Iteration: 40/50[==============] -Error: 0.0037612321  -Training_Accuracy:  91.60  -Test_Accuracy  92.42  -time: 1302.83 \n",
      "Iteration: 41/50[==============] -Error: 0.0037298746  -Training_Accuracy:  91.69  -Test_Accuracy  92.53  -time: 1334.36 \n",
      "Iteration: 42/50[==============] -Error: 0.0036918010  -Training_Accuracy:  91.74  -Test_Accuracy  92.58  -time: 1366.12 \n",
      "Iteration: 43/50[==============] -Error: 0.0036583955  -Training_Accuracy:  91.79  -Test_Accuracy  92.62  -time: 1397.58 \n",
      "Iteration: 44/50[==============] -Error: 0.0036261608  -Training_Accuracy:  91.83  -Test_Accuracy  92.65  -time: 1429.01 \n",
      "Iteration: 45/50[==============] -Error: 0.0035950698  -Training_Accuracy:  91.90  -Test_Accuracy  92.66  -time: 1460.55 \n",
      "Iteration: 46/50[==============] -Error: 0.0035658854  -Training_Accuracy:  91.95  -Test_Accuracy  92.71  -time: 1494.37 \n",
      "Iteration: 47/50[==============] -Error: 0.0035349301  -Training_Accuracy:  92.04  -Test_Accuracy  92.75  -time: 1525.43 \n",
      "Iteration: 48/50[==============] -Error: 0.0035081370  -Training_Accuracy:  92.05  -Test_Accuracy  92.80  -time: 1556.98 \n",
      "Iteration: 49/50[==============] -Error: 0.0034825854  -Training_Accuracy:  92.10  -Test_Accuracy  92.84  -time: 1588.31 \n",
      "Iteration: 50/50[==============] -Error: 0.0034573801  -Training_Accuracy:  92.15  -Test_Accuracy  92.89  -time: 1620.53 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 0.001 goes here \n",
    "\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_001 = NeuralNetwork(784,30,10, learning_rate = 0.001)\n",
    "\n",
    "#train the network\n",
    "mnist_net_001.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_001.save(\"Models/model_2-iterations_50-learning_0_001-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(guess(mnist_net_001,'9.bmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "mnist_net_001.load(\"Models/model_2-iterations_50-learning_0_001-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0060301559  -Training_Accuracy:  93.15  -Test_Accuracy  93.66  -time: 53.51 \n",
      "Iteration:  2/50[==============] -Error: 0.0029313411  -Training_Accuracy:  94.66  -Test_Accuracy  94.78  -time: 107.90 \n",
      "Iteration:  3/50[==============] -Error: 0.0026744835  -Training_Accuracy:  95.31  -Test_Accuracy  95.34  -time: 156.79 \n",
      "Iteration:  4/50[==============] -Error: 0.0023738606  -Training_Accuracy:  95.76  -Test_Accuracy  95.37  -time: 215.14 \n",
      "Iteration:  5/50[==============] -Error: 0.0022275188  -Training_Accuracy:  96.34  -Test_Accuracy  95.90  -time: 257.54 \n",
      "Iteration:  6/50[==============] -Error: 0.0021319063  -Training_Accuracy:  96.61  -Test_Accuracy  96.02  -time: 305.34 \n",
      "Iteration:  7/50[==============] -Error: 0.0019791560  -Training_Accuracy:  96.76  -Test_Accuracy  95.94  -time: 342.77 \n",
      "Iteration:  8/50[==============] -Error: 0.0018955668  -Training_Accuracy:  97.03  -Test_Accuracy  96.06  -time: 379.85 \n",
      "Iteration:  9/50[==============] -Error: 0.0017781650  -Training_Accuracy:  97.15  -Test_Accuracy  96.20  -time: 416.20 \n",
      "Iteration: 10/50[==============] -Error: 0.0017059513  -Training_Accuracy:  97.21  -Test_Accuracy  96.33  -time: 451.14 \n",
      "Iteration: 11/50[==============] -Error: 0.0016560767  -Training_Accuracy:  97.33  -Test_Accuracy  96.31  -time: 488.85 \n",
      "Iteration: 12/50[==============] -Error: 0.0015713873  -Training_Accuracy:  97.51  -Test_Accuracy  96.27  -time: 538.82 \n",
      "Iteration: 13/50[==============] -Error: 0.0014950233  -Training_Accuracy:  97.57  -Test_Accuracy  96.32  -time: 593.94 \n",
      "Iteration: 14/50[==============] -Error: 0.0014444416  -Training_Accuracy:  97.67  -Test_Accuracy  96.35  -time: 649.56 \n",
      "Iteration: 15/50[==============] -Error: 0.0014037361  -Training_Accuracy:  97.73  -Test_Accuracy  96.23  -time: 729.02 \n",
      "Iteration: 16/50[==============] -Error: 0.0013562645  -Training_Accuracy:  97.71  -Test_Accuracy  96.27  -time: 777.16 \n",
      "Iteration: 17/50[==============] -Error: 0.0013525106  -Training_Accuracy:  97.83  -Test_Accuracy  96.34  -time: 813.52 \n",
      "Iteration: 18/50[==============] -Error: 0.0013540196  -Training_Accuracy:  97.85  -Test_Accuracy  96.46  -time: 849.62 \n",
      "Iteration: 19/50[==============] -Error: 0.0012591738  -Training_Accuracy:  97.88  -Test_Accuracy  96.35  -time: 884.88 \n",
      "Iteration: 20/50[==============] -Error: 0.0012466930  -Training_Accuracy:  97.98  -Test_Accuracy  96.42  -time: 919.77 \n",
      "Iteration: 21/50[==============] -Error: 0.0012029047  -Training_Accuracy:  98.03  -Test_Accuracy  96.31  -time: 954.94 \n",
      "Iteration: 22/50[==============] -Error: 0.0011607582  -Training_Accuracy:  98.11  -Test_Accuracy  96.58  -time: 988.61 \n",
      "Iteration: 23/50[==============] -Error: 0.0011713060  -Training_Accuracy:  98.12  -Test_Accuracy  96.33  -time: 1027.71 \n",
      "Iteration: 24/50[==============] -Error: 0.0011643988  -Training_Accuracy:  98.04  -Test_Accuracy  96.39  -time: 1062.88 \n",
      "Iteration: 25/50[==============] -Error: 0.0011669088  -Training_Accuracy:  98.13  -Test_Accuracy  96.45  -time: 1098.70 \n",
      "Iteration: 26/50[==============] -Error: 0.0011055473  -Training_Accuracy:  98.13  -Test_Accuracy  96.45  -time: 1134.40 \n",
      "Iteration: 27/50[==============] -Error: 0.0010753694  -Training_Accuracy:  98.18  -Test_Accuracy  96.39  -time: 1169.17 \n",
      "Iteration: 28/50[==============] -Error: 0.0010828359  -Training_Accuracy:  98.30  -Test_Accuracy  96.61  -time: 1204.26 \n",
      "Iteration: 29/50[==============] -Error: 0.0010530454  -Training_Accuracy:  98.35  -Test_Accuracy  96.38  -time: 1239.77 \n",
      "Iteration: 30/50[==============] -Error: 0.0010631063  -Training_Accuracy:  98.31  -Test_Accuracy  96.40  -time: 1277.98 \n",
      "Iteration: 31/50[==============] -Error: 0.0010455498  -Training_Accuracy:  98.37  -Test_Accuracy  96.62  -time: 1315.75 \n",
      "Iteration: 32/50[==============] -Error: 0.0010273284  -Training_Accuracy:  98.38  -Test_Accuracy  96.48  -time: 1356.80 \n",
      "Iteration: 33/50[==============] -Error: 0.0010006640  -Training_Accuracy:  98.32  -Test_Accuracy  96.36  -time: 1402.18 \n",
      "Iteration: 34/50[==============] -Error: 0.0009708900  -Training_Accuracy:  98.26  -Test_Accuracy  96.27  -time: 1445.13 \n",
      "Iteration: 35/50[==============] -Error: 0.0009663231  -Training_Accuracy:  98.39  -Test_Accuracy  96.38  -time: 1483.85 \n",
      "Iteration: 36/50[==============] -Error: 0.0009395059  -Training_Accuracy:  98.27  -Test_Accuracy  96.25  -time: 1528.01 \n",
      "Iteration: 37/50[==============] -Error: 0.0009376542  -Training_Accuracy:  98.48  -Test_Accuracy  96.53  -time: 1572.55 \n",
      "Iteration: 38/50[==============] -Error: 0.0009346597  -Training_Accuracy:  98.47  -Test_Accuracy  96.40  -time: 1612.82 \n",
      "Iteration: 39/50[==============] -Error: 0.0008902625  -Training_Accuracy:  98.50  -Test_Accuracy  96.32  -time: 1654.33 \n",
      "Iteration: 40/50[==============] -Error: 0.0008931627  -Training_Accuracy:  98.49  -Test_Accuracy  96.35  -time: 1704.67 \n",
      "Iteration: 41/50[==============] -Error: 0.0008942941  -Training_Accuracy:  98.51  -Test_Accuracy  96.43  -time: 1752.68 \n",
      "Iteration: 42/50[==============] -Error: 0.0008740002  -Training_Accuracy:  98.53  -Test_Accuracy  96.37  -time: 1799.52 \n",
      "Iteration: 43/50[==============] -Error: 0.0008911273  -Training_Accuracy:  98.59  -Test_Accuracy  96.48  -time: 1847.32 \n",
      "Iteration: 44/50[==============] -Error: 0.0008544290  -Training_Accuracy:  98.63  -Test_Accuracy  96.46  -time: 1899.67 \n",
      "Iteration: 45/50[==============] -Error: 0.0008497344  -Training_Accuracy:  98.57  -Test_Accuracy  96.44  -time: 1947.50 \n",
      "Iteration: 46/50[==============] -Error: 0.0008276278  -Training_Accuracy:  98.61  -Test_Accuracy  96.36  -time: 1992.71 \n",
      "Iteration: 47/50[==============] -Error: 0.0007992582  -Training_Accuracy:  98.61  -Test_Accuracy  96.38  -time: 2039.05 \n",
      "Iteration: 48/50[==============] -Error: 0.0008144464  -Training_Accuracy:  98.58  -Test_Accuracy  96.31  -time: 2078.90 \n",
      "Iteration: 49/50[==============] -Error: 0.0007923044  -Training_Accuracy:  98.65  -Test_Accuracy  96.32  -time: 2120.48 \n",
      "Iteration: 50/50[==============] -Error: 0.0007897876  -Training_Accuracy:  98.64  -Test_Accuracy  96.32  -time: 2159.78 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 0.1 goes here \n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_1 = NeuralNetwork(784,30,10, learning_rate = 0.1)\n",
    "\n",
    "#train the network\n",
    "mnist_net_1.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_1.save(\"Models/model_3-iterations_50-learning_0_1-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "mnist_net_1.load(\"Models/model_3-iterations_50-learning_0_1-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sofiene\\Downloads\\DeepLearning\\transfer_functions.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0490721880  -Training_Accuracy:  20.54  -Test_Accuracy  20.75  -time: 42.74 \n",
      "Iteration:  2/50[==============] -Error: 0.0493199573  -Training_Accuracy:  17.24  -Test_Accuracy  17.00  -time: 82.14 \n",
      "Iteration:  3/50[==============] -Error: 0.0493199999  -Training_Accuracy:  19.06  -Test_Accuracy  18.77  -time: 115.33 \n",
      "Iteration:  4/50[==============] -Error: 0.0493199999  -Training_Accuracy:  24.70  -Test_Accuracy  24.23  -time: 148.51 \n",
      "Iteration:  5/50[==============] -Error: 0.0493199999  -Training_Accuracy:  15.24  -Test_Accuracy  14.56  -time: 181.55 \n",
      "Iteration:  6/50[==============] -Error: 0.0493199999  -Training_Accuracy:  16.79  -Test_Accuracy  16.32  -time: 214.56 \n",
      "Iteration:  7/50[==============] -Error: 0.0493199999  -Training_Accuracy:  9.23  -Test_Accuracy  9.21  -time: 247.70 \n",
      "Iteration:  8/50[==============] -Error: 0.0493199999  -Training_Accuracy:  11.04  -Test_Accuracy  11.15  -time: 280.39 \n",
      "Iteration:  9/50[==============] -Error: 0.0493199999  -Training_Accuracy:  16.85  -Test_Accuracy  17.46  -time: 313.43 \n",
      "Iteration: 10/50[==============] -Error: 0.0493199999  -Training_Accuracy:  20.66  -Test_Accuracy  21.52  -time: 346.28 \n",
      "Iteration: 11/50[==============] -Error: 0.0493199999  -Training_Accuracy:  18.46  -Test_Accuracy  18.86  -time: 379.48 \n",
      "Iteration: 12/50[==============] -Error: 0.0493199999  -Training_Accuracy:  15.95  -Test_Accuracy  16.24  -time: 412.26 \n",
      "Iteration: 13/50[==============] -Error: 0.0493199999  -Training_Accuracy:  18.45  -Test_Accuracy  18.52  -time: 445.98 \n",
      "Iteration: 14/50[==============] -Error: 0.0493199999  -Training_Accuracy:  14.26  -Test_Accuracy  13.73  -time: 478.99 \n",
      "Iteration: 15/50[==============] -Error: 0.0493199999  -Training_Accuracy:  20.37  -Test_Accuracy  21.45  -time: 511.90 \n",
      "Iteration: 16/50[==============] -Error: 0.0493199999  -Training_Accuracy:  28.47  -Test_Accuracy  29.08  -time: 549.10 \n",
      "Iteration: 17/50[==============] -Error: 0.0493199999  -Training_Accuracy:  28.42  -Test_Accuracy  28.37  -time: 585.94 \n",
      "Iteration: 18/50[==============] -Error: 0.0493199999  -Training_Accuracy:  29.44  -Test_Accuracy  30.87  -time: 623.48 \n",
      "Iteration: 19/50[==============] -Error: 0.0493199999  -Training_Accuracy:  19.59  -Test_Accuracy  20.62  -time: 659.85 \n",
      "Iteration: 20/50[==============] -Error: 0.0493199999  -Training_Accuracy:  20.39  -Test_Accuracy  21.22  -time: 696.72 \n",
      "Iteration: 21/50[==============] -Error: 0.0493199999  -Training_Accuracy:  14.92  -Test_Accuracy  15.03  -time: 732.92 \n",
      "Iteration: 22/50[==============] -Error: 0.0493199999  -Training_Accuracy:  11.49  -Test_Accuracy  11.15  -time: 769.64 \n",
      "Iteration: 23/50[==============] -Error: 0.0493199999  -Training_Accuracy:  10.92  -Test_Accuracy  11.05  -time: 806.05 \n",
      "Iteration: 24/50[==============] -Error: 0.0493199999  -Training_Accuracy:  17.07  -Test_Accuracy  17.65  -time: 842.26 \n",
      "Iteration: 25/50[==============] -Error: 0.0493199999  -Training_Accuracy:  15.68  -Test_Accuracy  15.96  -time: 878.60 \n",
      "Iteration: 26/50[==============] -Error: 0.0493199999  -Training_Accuracy:  13.95  -Test_Accuracy  13.91  -time: 915.02 \n",
      "Iteration: 27/50[==============] -Error: 0.0493199999  -Training_Accuracy:  13.90  -Test_Accuracy  13.90  -time: 951.47 \n",
      "Iteration: 28/50[==============] -Error: 0.0493199999  -Training_Accuracy:  15.38  -Test_Accuracy  15.34  -time: 988.09 \n",
      "Iteration: 29/50[==============] -Error: 0.0493199999  -Training_Accuracy:  14.89  -Test_Accuracy  14.63  -time: 1024.78 \n",
      "Iteration: 30/50[==============] -Error: 0.0493199999  -Training_Accuracy:  14.39  -Test_Accuracy  14.05  -time: 1061.17 \n",
      "Iteration: 31/50[==============] -Error: 0.0493200000  -Training_Accuracy:  13.82  -Test_Accuracy  13.48  -time: 1097.60 \n",
      "Iteration: 32/50[==============] -Error: 0.0493200000  -Training_Accuracy:  13.29  -Test_Accuracy  13.09  -time: 1133.84 \n",
      "Iteration: 33/50[==============] -Error: 0.0493200000  -Training_Accuracy:  14.16  -Test_Accuracy  14.14  -time: 1170.13 \n",
      "Iteration: 34/50[==============] -Error: 0.0493200000  -Training_Accuracy:  14.18  -Test_Accuracy  14.17  -time: 1206.71 \n",
      "Iteration: 35/50[==============] -Error: 0.0493200000  -Training_Accuracy:  14.62  -Test_Accuracy  14.76  -time: 1242.81 \n",
      "Iteration: 36/50[==============] -Error: 0.0493200000  -Training_Accuracy:  10.52  -Test_Accuracy  10.52  -time: 1278.93 \n",
      "Iteration: 37/50[==============] -Error: 0.0493199999  -Training_Accuracy:  16.30  -Test_Accuracy  16.57  -time: 1314.89 \n",
      "Iteration: 38/50[==============] -Error: 0.0493200000  -Training_Accuracy:  13.29  -Test_Accuracy  13.11  -time: 1350.84 \n",
      "Iteration: 39/50[==============] -Error: 0.0493200000  -Training_Accuracy:  17.78  -Test_Accuracy  18.27  -time: 1387.43 \n",
      "Iteration: 40/50[==============] -Error: 0.0493200000  -Training_Accuracy:  14.92  -Test_Accuracy  14.90  -time: 1423.55 \n",
      "Iteration: 41/50[==============] -Error: 0.0493200000  -Training_Accuracy:  14.86  -Test_Accuracy  14.86  -time: 1459.63 \n",
      "Iteration: 42/50[==============] -Error: 0.0493200000  -Training_Accuracy:  11.97  -Test_Accuracy  12.11  -time: 1495.63 \n",
      "Iteration: 43/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.86  -Test_Accuracy  16.86  -time: 1531.76 \n",
      "Iteration: 44/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.86  -time: 1568.51 \n",
      "Iteration: 45/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.85  -time: 1604.25 \n",
      "Iteration: 46/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.85  -time: 1640.41 \n",
      "Iteration: 47/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.87  -time: 1676.97 \n",
      "Iteration: 48/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.87  -time: 1712.80 \n",
      "Iteration: 49/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.86  -time: 1749.31 \n",
      "Iteration: 50/50[==============] -Error: 0.0493200000  -Training_Accuracy:  16.85  -Test_Accuracy  16.82  -time: 1785.70 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 10 goes here \n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_10 = NeuralNetwork(784,30,10, learning_rate = 10)\n",
    "\n",
    "#train the network\n",
    "mnist_net_10.train(training_data,validation_data, test_data)\n",
    "\n",
    "\n",
    "#save the model\n",
    "mnist_net_10.save(\"Models/model_4-iterations_50-learning_10-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "mnist_net_10.load(\"Models/model_4-iterations_50-learning_10-hidden_30-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Figures/figure.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We observe that the two best \"learners\" have learning rates of 0.1 and 1. For a learning rate of 0.001 the learning process is too slow, the weights don't change much and so it takes many iterations to achieve a good result (taking also the risk of getting stuck in local minimum instead of reaching the global minimum of the error function). As for the learning rate of 10, the weights make way to big changes, not allowing them to stabilize around any minimum of the error functions, that's why the accuracy just changes \"randomly\" and stays low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <b> Question 2.2.2 : </b> initialize all weights to 0.  Plot the training accuracy curve.\n",
    "Comment your results\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0234527075  -Training_Accuracy:  45.38  -Test_Accuracy  45.64  -time: 36.55 \n",
      "Iteration:  2/50[==============] -Error: 0.0198509161  -Training_Accuracy:  46.29  -Test_Accuracy  46.08  -time: 73.84 \n",
      "Iteration:  3/50[==============] -Error: 0.0198296131  -Training_Accuracy:  43.82  -Test_Accuracy  44.36  -time: 110.87 \n",
      "Iteration:  4/50[==============] -Error: 0.0186943195  -Training_Accuracy:  49.66  -Test_Accuracy  49.46  -time: 167.77 \n",
      "Iteration:  5/50[==============] -Error: 0.0202792650  -Training_Accuracy:  44.54  -Test_Accuracy  44.94  -time: 221.50 \n",
      "Iteration:  6/50[==============] -Error: 0.0204569256  -Training_Accuracy:  42.50  -Test_Accuracy  42.62  -time: 267.67 \n",
      "Iteration:  7/50[==============] -Error: 0.0205091881  -Training_Accuracy:  45.25  -Test_Accuracy  45.16  -time: 325.61 \n",
      "Iteration:  8/50[==============] -Error: 0.0203442843  -Training_Accuracy:  47.42  -Test_Accuracy  47.65  -time: 378.84 \n",
      "Iteration:  9/50[==============] -Error: 0.0198786981  -Training_Accuracy:  45.64  -Test_Accuracy  45.47  -time: 432.13 \n",
      "Iteration: 10/50[==============] -Error: 0.0212334268  -Training_Accuracy:  42.13  -Test_Accuracy  42.46  -time: 485.04 \n",
      "Iteration: 11/50[==============] -Error: 0.0206468016  -Training_Accuracy:  42.90  -Test_Accuracy  42.61  -time: 538.84 \n",
      "Iteration: 12/50[==============] -Error: 0.0207053302  -Training_Accuracy:  43.68  -Test_Accuracy  43.77  -time: 592.02 \n",
      "Iteration: 13/50[==============] -Error: 0.0206023609  -Training_Accuracy:  48.95  -Test_Accuracy  48.45  -time: 645.23 \n",
      "Iteration: 14/50[==============] -Error: 0.0207356947  -Training_Accuracy:  46.41  -Test_Accuracy  46.21  -time: 697.96 \n",
      "Iteration: 15/50[==============] -Error: 0.0212063409  -Training_Accuracy:  43.17  -Test_Accuracy  43.02  -time: 751.21 \n",
      "Iteration: 16/50[==============] -Error: 0.0205341147  -Training_Accuracy:  46.48  -Test_Accuracy  46.76  -time: 804.15 \n",
      "Iteration: 17/50[==============] -Error: 0.0206487381  -Training_Accuracy:  45.58  -Test_Accuracy  45.61  -time: 857.46 \n",
      "Iteration: 18/50[==============] -Error: 0.0212800496  -Training_Accuracy:  41.09  -Test_Accuracy  41.22  -time: 911.04 \n",
      "Iteration: 19/50[==============] -Error: 0.0202544687  -Training_Accuracy:  48.11  -Test_Accuracy  47.95  -time: 963.71 \n",
      "Iteration: 20/50[==============] -Error: 0.0215049546  -Training_Accuracy:  46.26  -Test_Accuracy  46.41  -time: 1016.51 \n",
      "Iteration: 21/50[==============] -Error: 0.0208678341  -Training_Accuracy:  47.76  -Test_Accuracy  47.42  -time: 1067.09 \n",
      "Iteration: 22/50[==============] -Error: 0.0208569208  -Training_Accuracy:  47.89  -Test_Accuracy  47.30  -time: 1111.94 \n",
      "Iteration: 23/50[==============] -Error: 0.0205258399  -Training_Accuracy:  49.30  -Test_Accuracy  48.83  -time: 1161.69 \n",
      "Iteration: 24/50[==============] -Error: 0.0200777087  -Training_Accuracy:  38.05  -Test_Accuracy  38.02  -time: 1211.60 \n",
      "Iteration: 25/50[==============] -Error: 0.0206420267  -Training_Accuracy:  46.21  -Test_Accuracy  46.01  -time: 1261.94 \n",
      "Iteration: 26/50[==============] -Error: 0.0210782277  -Training_Accuracy:  39.89  -Test_Accuracy  39.79  -time: 1312.24 \n",
      "Iteration: 27/50[==============] -Error: 0.0213846197  -Training_Accuracy:  45.61  -Test_Accuracy  45.15  -time: 1362.58 \n",
      "Iteration: 28/50[==============] -Error: 0.0207030848  -Training_Accuracy:  43.76  -Test_Accuracy  43.07  -time: 1413.30 \n",
      "Iteration: 29/50[==============] -Error: 0.0204157779  -Training_Accuracy:  46.84  -Test_Accuracy  46.84  -time: 1462.00 \n",
      "Iteration: 30/50[==============] -Error: 0.0204470725  -Training_Accuracy:  43.32  -Test_Accuracy  43.33  -time: 1512.51 \n",
      "Iteration: 31/50[==============] -Error: 0.0207308626  -Training_Accuracy:  41.83  -Test_Accuracy  41.54  -time: 1561.69 \n",
      "Iteration: 32/50[==============] -Error: 0.0209438335  -Training_Accuracy:  47.73  -Test_Accuracy  47.69  -time: 1610.05 \n",
      "Iteration: 33/50[==============] -Error: 0.0208128743  -Training_Accuracy:  44.95  -Test_Accuracy  44.77  -time: 1655.75 \n",
      "Iteration: 34/50[==============] -Error: 0.0202395041  -Training_Accuracy:  46.88  -Test_Accuracy  46.63  -time: 1695.67 \n",
      "Iteration: 35/50[==============] -Error: 0.0206353387  -Training_Accuracy:  44.38  -Test_Accuracy  44.12  -time: 1731.70 \n",
      "Iteration: 36/50[==============] -Error: 0.0203675788  -Training_Accuracy:  45.30  -Test_Accuracy  45.77  -time: 1769.25 \n",
      "Iteration: 37/50[==============] -Error: 0.0204383902  -Training_Accuracy:  45.66  -Test_Accuracy  45.70  -time: 1806.09 \n",
      "Iteration: 38/50[==============] -Error: 0.0201830652  -Training_Accuracy:  44.61  -Test_Accuracy  44.71  -time: 1843.20 \n",
      "Iteration: 39/50[==============] -Error: 0.0211390113  -Training_Accuracy:  44.87  -Test_Accuracy  44.72  -time: 1880.35 \n",
      "Iteration: 40/50[==============] -Error: 0.0208574642  -Training_Accuracy:  43.14  -Test_Accuracy  42.90  -time: 1918.91 \n",
      "Iteration: 41/50[==============] -Error: 0.0208968319  -Training_Accuracy:  46.86  -Test_Accuracy  46.35  -time: 1956.09 \n",
      "Iteration: 42/50[==============] -Error: 0.0207393579  -Training_Accuracy:  43.13  -Test_Accuracy  42.81  -time: 1993.36 \n",
      "Iteration: 43/50[==============] -Error: 0.0206248369  -Training_Accuracy:  47.63  -Test_Accuracy  47.89  -time: 2030.91 \n",
      "Iteration: 44/50[==============] -Error: 0.0212158614  -Training_Accuracy:  44.09  -Test_Accuracy  43.99  -time: 2067.02 \n",
      "Iteration: 45/50[==============] -Error: 0.0208462588  -Training_Accuracy:  43.29  -Test_Accuracy  43.77  -time: 2103.71 \n",
      "Iteration: 46/50[==============] -Error: 0.0204411979  -Training_Accuracy:  44.44  -Test_Accuracy  44.07  -time: 2141.14 \n",
      "Iteration: 47/50[==============] -Error: 0.0210038347  -Training_Accuracy:  39.92  -Test_Accuracy  39.78  -time: 2177.52 \n",
      "Iteration: 48/50[==============] -Error: 0.0210538487  -Training_Accuracy:  44.67  -Test_Accuracy  44.58  -time: 2215.28 \n",
      "Iteration: 49/50[==============] -Error: 0.0201278933  -Training_Accuracy:  44.18  -Test_Accuracy  44.30  -time: 2253.87 \n",
      "Iteration: 50/50[==============] -Error: 0.0207058416  -Training_Accuracy:  44.30  -Test_Accuracy  44.16  -time: 2294.86 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_0 = NeuralNetwork(784,30,10)\n",
    "#initialize weigths\n",
    "wi=np.zeros((785,30))\n",
    "wo=np.zeros((31,10))\n",
    "mnist_net_0.weights_initialisation(wi,wo)\n",
    "\n",
    "#train the network\n",
    "mnist_net_0.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_0.save(\"Models/model_5-iterations_50-learning_1-hidden_30-output_10-weights_0.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "mnist_net_0.load(\"Models/model_5-iterations_50-learning_1-hidden_30-output_10-weights_0.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Figures/model5.png\", width=\"700\" height=\"900\"> \n",
    "<img src=\"Figures/model5_1.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We notice that initializing all the weights at zero isn't a good idea as we start from a very low accuracy (45%) and this doesn't improve much (it even decreases) in 50 iterations because the weights won't get too far from 0 (what we add to them is very small because again the weights are very close to 0). That's why actually we initialize the weights at random according to a normal curve following Yann Lecun method in his 1988's paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.3 : </b> Try with a different transfer function (such as tanh).\n",
    " File transfer_functions.py provides you the python implementation of the tanh function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.6478772046  -Training_Accuracy:  11.48  -Test_Accuracy  10.72  -time: 26.04 \n",
      "Iteration:  2/50[==============] -Error: 0.5893505689  -Training_Accuracy:  11.45  -Test_Accuracy  10.72  -time: 52.58 \n",
      "Iteration:  3/50[==============] -Error: 0.4506799896  -Training_Accuracy:  11.45  -Test_Accuracy  10.72  -time: 78.66 \n",
      "Iteration:  4/50[==============] -Error: 0.4506799913  -Training_Accuracy:  11.36  -Test_Accuracy  10.64  -time: 104.40 \n",
      "Iteration:  5/50[==============] -Error: 0.4506799791  -Training_Accuracy:  11.39  -Test_Accuracy  10.67  -time: 130.45 \n",
      "Iteration:  6/50[==============] -Error: 0.4506799645  -Training_Accuracy:  11.39  -Test_Accuracy  10.67  -time: 155.57 \n",
      "Iteration:  7/50[==============] -Error: 0.4506799549  -Training_Accuracy:  11.39  -Test_Accuracy  10.67  -time: 181.88 \n",
      "Iteration:  8/50[==============] -Error: 0.4506799419  -Training_Accuracy:  11.38  -Test_Accuracy  10.67  -time: 207.55 \n",
      "Iteration:  9/50[==============] -Error: 0.4506799263  -Training_Accuracy:  11.38  -Test_Accuracy  10.67  -time: 232.68 \n",
      "Iteration: 10/50[==============] -Error: 0.4506798545  -Training_Accuracy:  11.38  -Test_Accuracy  10.67  -time: 257.88 \n",
      "Iteration: 11/50[==============] -Error: 0.4772599485  -Training_Accuracy:  12.03  -Test_Accuracy  12.19  -time: 283.28 \n",
      "Iteration: 12/50[==============] -Error: 0.4506722632  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 308.43 \n",
      "Iteration: 13/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 333.93 \n",
      "Iteration: 14/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 360.06 \n",
      "Iteration: 15/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 385.71 \n",
      "Iteration: 16/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 411.51 \n",
      "Iteration: 17/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 438.27 \n",
      "Iteration: 18/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 464.07 \n",
      "Iteration: 19/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 491.28 \n",
      "Iteration: 20/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.14  -Test_Accuracy  10.30  -time: 517.10 \n",
      "Iteration: 21/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.14  -Test_Accuracy  10.30  -time: 543.41 \n",
      "Iteration: 22/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.14  -Test_Accuracy  10.30  -time: 569.98 \n",
      "Iteration: 23/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.14  -Test_Accuracy  10.30  -time: 595.29 \n",
      "Iteration: 24/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.14  -Test_Accuracy  10.30  -time: 621.54 \n",
      "Iteration: 25/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 647.38 \n",
      "Iteration: 26/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 672.55 \n",
      "Iteration: 27/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 698.09 \n",
      "Iteration: 28/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 723.64 \n",
      "Iteration: 29/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 749.82 \n",
      "Iteration: 30/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 776.23 \n",
      "Iteration: 31/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 801.85 \n",
      "Iteration: 32/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 827.85 \n",
      "Iteration: 33/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 853.86 \n",
      "Iteration: 34/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 880.04 \n",
      "Iteration: 35/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 905.46 \n",
      "Iteration: 36/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 931.26 \n",
      "Iteration: 37/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 956.08 \n",
      "Iteration: 38/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 982.44 \n",
      "Iteration: 39/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 1007.51 \n",
      "Iteration: 40/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.30  -time: 1032.65 \n",
      "Iteration: 41/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.31  -time: 1058.64 \n",
      "Iteration: 42/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.31  -time: 1083.96 \n",
      "Iteration: 43/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.31  -time: 1110.29 \n",
      "Iteration: 44/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.31  -time: 1136.48 \n",
      "Iteration: 45/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.31  -time: 1161.80 \n",
      "Iteration: 46/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.32  -time: 1187.61 \n",
      "Iteration: 47/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.32  -time: 1213.38 \n",
      "Iteration: 48/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.32  -time: 1240.47 \n",
      "Iteration: 49/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.32  -time: 1266.28 \n",
      "Iteration: 50/50[==============] -Error: 0.4506800000  -Training_Accuracy:  10.15  -Test_Accuracy  10.32  -time: 1291.39 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_th = NeuralNetwork(784,30,10, transfer_function = tanh)\n",
    "\n",
    "#train the network\n",
    "mnist_net_th.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_th.save(\"Models/model_6-iterations_50-learning_1-hidden_30-output_10-transfer_tanh.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "mnist_net_th.load(\"Models/model_6-iterations_50-learning_1-hidden_30-output_10-transfer_tanh.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Figures/model6.png\", width=\"700\" height=\"900\"> \n",
    "<img src=\"Figures/model6_1.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We observe that the learning process doesn't work with the tanh transfer function as the training and testing accuracies decrease instead of increasing. This is probably because of the negative values that the function takes for a negative argument, whereas the sigmoid always stays positive and tends to 0 at -infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<b> Question 2.2.4 : </b>  Add more neurons in the hidden layer (try with 100, 200, 300). Plot the curve representing the validation accuracy versus the number of neurons in the hidden layer.  (Choose and justify other hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0037153697  -Training_Accuracy:  95.50  -Test_Accuracy  95.79  -time: 57.61 \n",
      "Iteration:  2/50[==============] -Error: 0.0023279583  -Training_Accuracy:  96.01  -Test_Accuracy  95.67  -time: 118.80 \n",
      "Iteration:  3/50[==============] -Error: 0.0021124638  -Training_Accuracy:  97.05  -Test_Accuracy  96.55  -time: 183.80 \n",
      "Iteration:  4/50[==============] -Error: 0.0019784113  -Training_Accuracy:  97.31  -Test_Accuracy  96.80  -time: 243.82 \n",
      "Iteration:  5/50[==============] -Error: 0.0015845787  -Training_Accuracy:  97.43  -Test_Accuracy  96.85  -time: 308.36 \n",
      "Iteration:  6/50[==============] -Error: 0.0014779146  -Training_Accuracy:  97.57  -Test_Accuracy  96.54  -time: 373.99 \n",
      "Iteration:  7/50[==============] -Error: 0.0014896037  -Training_Accuracy:  97.72  -Test_Accuracy  97.00  -time: 440.61 \n",
      "Iteration:  8/50[==============] -Error: 0.0014474664  -Training_Accuracy:  97.91  -Test_Accuracy  96.94  -time: 506.83 \n",
      "Iteration:  9/50[==============] -Error: 0.0013470043  -Training_Accuracy:  97.90  -Test_Accuracy  96.92  -time: 575.59 \n",
      "Iteration: 10/50[==============] -Error: 0.0013366841  -Training_Accuracy:  98.06  -Test_Accuracy  96.96  -time: 638.15 \n",
      "Iteration: 11/50[==============] -Error: 0.0011825368  -Training_Accuracy:  98.14  -Test_Accuracy  96.89  -time: 699.19 \n",
      "Iteration: 12/50[==============] -Error: 0.0011805820  -Training_Accuracy:  98.32  -Test_Accuracy  96.90  -time: 758.43 \n",
      "Iteration: 13/50[==============] -Error: 0.0010723870  -Training_Accuracy:  98.45  -Test_Accuracy  97.11  -time: 812.68 \n",
      "Iteration: 14/50[==============] -Error: 0.0010349319  -Training_Accuracy:  98.51  -Test_Accuracy  96.99  -time: 868.16 \n",
      "Iteration: 15/50[==============] -Error: 0.0008933721  -Training_Accuracy:  98.64  -Test_Accuracy  97.19  -time: 922.81 \n",
      "Iteration: 16/50[==============] -Error: 0.0009296559  -Training_Accuracy:  98.56  -Test_Accuracy  97.09  -time: 976.91 \n",
      "Iteration: 17/50[==============] -Error: 0.0009027983  -Training_Accuracy:  98.57  -Test_Accuracy  97.29  -time: 1031.63 \n",
      "Iteration: 18/50[==============] -Error: 0.0008001381  -Training_Accuracy:  98.74  -Test_Accuracy  97.22  -time: 1086.53 \n",
      "Iteration: 19/50[==============] -Error: 0.0008352784  -Training_Accuracy:  98.79  -Test_Accuracy  97.06  -time: 1141.36 \n",
      "Iteration: 20/50[==============] -Error: 0.0008021603  -Training_Accuracy:  98.71  -Test_Accuracy  97.26  -time: 1196.57 \n",
      "Iteration: 21/50[==============] -Error: 0.0006798830  -Training_Accuracy:  98.70  -Test_Accuracy  97.18  -time: 1257.40 \n",
      "Iteration: 22/50[==============] -Error: 0.0006998475  -Training_Accuracy:  98.88  -Test_Accuracy  97.22  -time: 1327.73 \n",
      "Iteration: 23/50[==============] -Error: 0.0006768746  -Training_Accuracy:  98.94  -Test_Accuracy  97.07  -time: 1399.45 \n",
      "Iteration: 24/50[==============] -Error: 0.0006001885  -Training_Accuracy:  99.05  -Test_Accuracy  97.23  -time: 1467.55 \n",
      "Iteration: 25/50[==============] -Error: 0.0006548502  -Training_Accuracy:  98.99  -Test_Accuracy  97.35  -time: 1526.98 \n",
      "Iteration: 26/50[==============] -Error: 0.0006204163  -Training_Accuracy:  99.00  -Test_Accuracy  97.39  -time: 1599.95 \n",
      "Iteration: 27/50[==============] -Error: 0.0006273023  -Training_Accuracy:  99.10  -Test_Accuracy  97.29  -time: 1674.57 \n",
      "Iteration: 28/50[==============] -Error: 0.0005843388  -Training_Accuracy:  99.18  -Test_Accuracy  97.45  -time: 1747.89 \n",
      "Iteration: 29/50[==============] -Error: 0.0005293742  -Training_Accuracy:  99.15  -Test_Accuracy  97.37  -time: 1822.58 \n",
      "Iteration: 30/50[==============] -Error: 0.0005617118  -Training_Accuracy:  99.19  -Test_Accuracy  97.26  -time: 1899.56 \n",
      "Iteration: 31/50[==============] -Error: 0.0004658270  -Training_Accuracy:  99.19  -Test_Accuracy  97.30  -time: 1972.58 \n",
      "Iteration: 32/50[==============] -Error: 0.0004386841  -Training_Accuracy:  99.28  -Test_Accuracy  97.37  -time: 2046.28 \n",
      "Iteration: 33/50[==============] -Error: 0.0005071910  -Training_Accuracy:  99.27  -Test_Accuracy  97.44  -time: 2121.63 \n",
      "Iteration: 34/50[==============] -Error: 0.0004408497  -Training_Accuracy:  99.32  -Test_Accuracy  97.21  -time: 2194.74 \n",
      "Iteration: 35/50[==============] -Error: 0.0003964684  -Training_Accuracy:  99.33  -Test_Accuracy  97.33  -time: 2268.75 \n",
      "Iteration: 36/50[==============] -Error: 0.0004486603  -Training_Accuracy:  99.34  -Test_Accuracy  97.45  -time: 2342.86 \n",
      "Iteration: 37/50[==============] -Error: 0.0004318215  -Training_Accuracy:  99.39  -Test_Accuracy  97.31  -time: 2415.23 \n",
      "Iteration: 38/50[==============] -Error: 0.0004227231  -Training_Accuracy:  99.36  -Test_Accuracy  97.17  -time: 2489.96 \n",
      "Iteration: 39/50[==============] -Error: 0.0003406298  -Training_Accuracy:  99.41  -Test_Accuracy  97.25  -time: 2563.68 \n",
      "Iteration: 40/50[==============] -Error: 0.0003448496  -Training_Accuracy:  99.38  -Test_Accuracy  97.21  -time: 2636.46 \n",
      "Iteration: 41/50[==============] -Error: 0.0003935300  -Training_Accuracy:  99.40  -Test_Accuracy  97.44  -time: 2710.74 \n",
      "Iteration: 42/50[==============] -Error: 0.0003315475  -Training_Accuracy:  99.39  -Test_Accuracy  97.36  -time: 2790.85 \n",
      "Iteration: 43/50[==============] -Error: 0.0003850670  -Training_Accuracy:  99.37  -Test_Accuracy  97.43  -time: 2869.32 \n",
      "Iteration: 44/50[==============] -Error: 0.0003366965  -Training_Accuracy:  99.44  -Test_Accuracy  97.30  -time: 2948.53 \n",
      "Iteration: 45/50[==============] -Error: 0.0003314527  -Training_Accuracy:  99.44  -Test_Accuracy  97.34  -time: 3028.34 \n",
      "Iteration: 46/50[==============] -Error: 0.0003068024  -Training_Accuracy:  99.46  -Test_Accuracy  97.25  -time: 3107.59 \n",
      "Iteration: 47/50[==============] -Error: 0.0003210827  -Training_Accuracy:  99.46  -Test_Accuracy  97.42  -time: 3171.80 \n",
      "Iteration: 48/50[==============] -Error: 0.0003509958  -Training_Accuracy:  99.50  -Test_Accuracy  97.43  -time: 3232.76 \n",
      "Iteration: 49/50[==============] -Error: 0.0003151412  -Training_Accuracy:  99.49  -Test_Accuracy  97.49  -time: 3293.77 \n",
      "Iteration: 50/50[==============] -Error: 0.0003120642  -Training_Accuracy:  99.50  -Test_Accuracy  97.34  -time: 3355.37 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "#hidden = 100\n",
    "\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_100 = NeuralNetwork(784,100,10)\n",
    "\n",
    "#train the network\n",
    "mnist_net_100.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_100.save(\"Models/model_7-iterations_50-learning_1-hidden_100-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from NeuralNetwork import * \n",
    "mnist_net_100 = NeuralNetwork(784,100,10)\n",
    "mnist_net_100.load(\"Models/model_7-iterations_50-learning_1-hidden_100-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 4), ('5', 5), ('9', 9), ('7', 3), ('2', 2), ('3', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(guess_list(mnist_net_100,['4.bmp','5.bmp','9.bmp','7.png','2.png','3.png']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0035903356  -Training_Accuracy:  95.76  -Test_Accuracy  95.82  -time: 237.94 \n",
      "Iteration:  2/50[==============] -Error: 0.0021528050  -Training_Accuracy:  96.39  -Test_Accuracy  96.41  -time: 455.16 \n",
      "Iteration:  3/50[==============] -Error: 0.0017053198  -Training_Accuracy:  97.24  -Test_Accuracy  96.63  -time: 674.90 \n",
      "Iteration:  4/50[==============] -Error: 0.0013847143  -Training_Accuracy:  97.76  -Test_Accuracy  96.92  -time: 917.60 \n",
      "Iteration:  5/50[==============] -Error: 0.0012055639  -Training_Accuracy:  97.33  -Test_Accuracy  96.55  -time: 1138.02 \n",
      "Iteration:  6/50[==============] -Error: 0.0012847442  -Training_Accuracy:  98.17  -Test_Accuracy  97.27  -time: 1395.59 \n",
      "Iteration:  7/50[==============] -Error: 0.0011438250  -Training_Accuracy:  98.48  -Test_Accuracy  97.45  -time: 1645.94 \n",
      "Iteration:  8/50[==============] -Error: 0.0009847003  -Training_Accuracy:  98.60  -Test_Accuracy  97.37  -time: 1892.42 \n",
      "Iteration:  9/50[==============] -Error: 0.0009717713  -Training_Accuracy:  98.58  -Test_Accuracy  97.38  -time: 2095.20 \n",
      "Iteration: 10/50[==============] -Error: 0.0008355797  -Training_Accuracy:  98.50  -Test_Accuracy  97.14  -time: 2289.00 \n",
      "Iteration: 11/50[==============] -Error: 0.0008587962  -Training_Accuracy:  98.57  -Test_Accuracy  97.15  -time: 2485.32 \n",
      "Iteration: 12/50[==============] -Error: 0.0007224065  -Training_Accuracy:  98.88  -Test_Accuracy  97.27  -time: 2685.81 \n",
      "Iteration: 13/50[==============] -Error: 0.0007146492  -Training_Accuracy:  98.77  -Test_Accuracy  97.20  -time: 2885.96 \n",
      "Iteration: 14/50[==============] -Error: 0.0006129278  -Training_Accuracy:  99.04  -Test_Accuracy  97.40  -time: 3084.87 \n",
      "Iteration: 15/50[==============] -Error: 0.0006509291  -Training_Accuracy:  99.03  -Test_Accuracy  97.32  -time: 3284.00 \n",
      "Iteration: 16/50[==============] -Error: 0.0005734289  -Training_Accuracy:  99.23  -Test_Accuracy  97.57  -time: 3519.56 \n",
      "Iteration: 17/50[==============] -Error: 0.0006041108  -Training_Accuracy:  99.19  -Test_Accuracy  97.53  -time: 3742.88 \n",
      "Iteration: 18/50[==============] -Error: 0.0005048051  -Training_Accuracy:  99.21  -Test_Accuracy  97.50  -time: 3959.65 \n",
      "Iteration: 19/50[==============] -Error: 0.0004839656  -Training_Accuracy:  99.25  -Test_Accuracy  97.61  -time: 4181.66 \n",
      "Iteration: 20/50[==============] -Error: 0.0004135093  -Training_Accuracy:  99.31  -Test_Accuracy  97.66  -time: 4416.61 \n",
      "Iteration: 21/50[==============] -Error: 0.0003752539  -Training_Accuracy:  99.33  -Test_Accuracy  97.71  -time: 4651.83 \n",
      "Iteration: 22/50[==============] -Error: 0.0004220797  -Training_Accuracy:  99.35  -Test_Accuracy  97.66  -time: 4882.55 \n",
      "Iteration: 23/50[==============] -Error: 0.0003149259  -Training_Accuracy:  99.48  -Test_Accuracy  97.68  -time: 5100.03 \n",
      "Iteration: 24/50[==============] -Error: 0.0002799409  -Training_Accuracy:  99.46  -Test_Accuracy  97.68  -time: 5315.23 \n",
      "Iteration: 25/50[==============] -Error: 0.0002798622  -Training_Accuracy:  99.52  -Test_Accuracy  97.66  -time: 5531.07 \n",
      "Iteration: 26/50[==============] -Error: 0.0002673688  -Training_Accuracy:  99.53  -Test_Accuracy  97.75  -time: 5745.35 \n",
      "Iteration: 27/50[==============] -Error: 0.0002829227  -Training_Accuracy:  99.55  -Test_Accuracy  97.77  -time: 5961.36 \n",
      "Iteration: 28/50[==============] -Error: 0.0002103134  -Training_Accuracy:  99.56  -Test_Accuracy  97.77  -time: 6149.95 \n",
      "Iteration: 29/50[==============] -Error: 0.0002366105  -Training_Accuracy:  99.55  -Test_Accuracy  97.85  -time: 6351.09 \n",
      "Iteration: 30/50[==============] -Error: 0.0002347685  -Training_Accuracy:  99.60  -Test_Accuracy  97.87  -time: 6559.98 \n",
      "Iteration: 31/50[==============] -Error: 0.0002129150  -Training_Accuracy:  99.62  -Test_Accuracy  97.91  -time: 6798.14 \n",
      "Iteration: 32/50[==============] -Error: 0.0001688306  -Training_Accuracy:  99.63  -Test_Accuracy  97.86  -time: 7005.38 \n",
      "Iteration: 33/50[==============] -Error: 0.0001730419  -Training_Accuracy:  99.65  -Test_Accuracy  97.82  -time: 7212.59 \n",
      "Iteration: 34/50[==============] -Error: 0.0001465848  -Training_Accuracy:  99.65  -Test_Accuracy  97.82  -time: 7409.83 \n",
      "Iteration: 35/50[==============] -Error: 0.0001361011  -Training_Accuracy:  99.66  -Test_Accuracy  97.88  -time: 7608.71 \n",
      "Iteration: 36/50[==============] -Error: 0.0001338659  -Training_Accuracy:  99.67  -Test_Accuracy  97.85  -time: 7836.35 \n",
      "Iteration: 37/50[==============] -Error: 0.0001292939  -Training_Accuracy:  99.68  -Test_Accuracy  97.87  -time: 8007.22 \n",
      "Iteration: 38/50[==============] -Error: 0.0001196617  -Training_Accuracy:  99.69  -Test_Accuracy  97.90  -time: 8166.60 \n",
      "Iteration: 39/50[==============] -Error: 0.0001187867  -Training_Accuracy:  99.69  -Test_Accuracy  97.90  -time: 8326.85 \n",
      "Iteration: 40/50[==============] -Error: 0.0001182412  -Training_Accuracy:  99.69  -Test_Accuracy  97.86  -time: 8487.06 \n",
      "Iteration: 41/50[==============] -Error: 0.0001161966  -Training_Accuracy:  99.70  -Test_Accuracy  97.86  -time: 8647.45 \n",
      "Iteration: 42/50[==============] -Error: 0.0001158327  -Training_Accuracy:  99.70  -Test_Accuracy  97.89  -time: 8808.37 \n",
      "Iteration: 43/50[==============] -Error: 0.0001150730  -Training_Accuracy:  99.70  -Test_Accuracy  97.96  -time: 8967.93 \n",
      "Iteration: 44/50[==============] -Error: 0.0001146664  -Training_Accuracy:  99.70  -Test_Accuracy  97.94  -time: 9127.54 \n",
      "Iteration: 45/50[==============] -Error: 0.0001140684  -Training_Accuracy:  99.70  -Test_Accuracy  97.92  -time: 9286.63 \n",
      "Iteration: 46/50[==============] -Error: 0.0001137906  -Training_Accuracy:  99.71  -Test_Accuracy  97.96  -time: 9446.42 \n",
      "Iteration: 47/50[==============] -Error: 0.0001136421  -Training_Accuracy:  99.70  -Test_Accuracy  97.97  -time: 9606.04 \n",
      "Iteration: 48/50[==============] -Error: 0.0001137019  -Training_Accuracy:  99.70  -Test_Accuracy  97.99  -time: 9772.65 \n",
      "Iteration: 49/50[==============] -Error: 0.0001136230  -Training_Accuracy:  99.70  -Test_Accuracy  97.94  -time: 9942.16 \n",
      "Iteration: 50/50[==============] -Error: 0.0001130757  -Training_Accuracy:  99.71  -Test_Accuracy  97.98  -time: 10113.83 \n"
     ]
    }
   ],
   "source": [
    "#hidden = 200\n",
    "\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_200 = NeuralNetwork(784,200,10)\n",
    "\n",
    "#train the network\n",
    "mnist_net_200.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_200.save(\"Models/model_8-iterations_50-learning_1-hidden_200-output_10.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/10[==============] -Error: 0.0039424171  -Training_Accuracy:  95.82  -Test_Accuracy  95.89  -time: 340.70 \n",
      "Iteration:  2/10[==============] -Error: 0.0019676787  -Training_Accuracy:  96.50  -Test_Accuracy  96.33  -time: 678.60 \n",
      "Iteration:  3/10[==============] -Error: 0.0017043673  -Training_Accuracy:  97.32  -Test_Accuracy  96.91  -time: 1066.38 \n",
      "Iteration:  4/10[==============] -Error: 0.0014450584  -Training_Accuracy:  97.39  -Test_Accuracy  96.76  -time: 1350.48 \n",
      "Iteration:  5/10[==============] -Error: 0.0012775595  -Training_Accuracy:  97.39  -Test_Accuracy  96.85  -time: 1614.36 \n",
      "Iteration:  6/10[==============] -Error: 0.0012865588  -Training_Accuracy:  97.44  -Test_Accuracy  96.36  -time: 1880.67 \n",
      "Iteration:  7/10[==============] -Error: 0.0011278360  -Training_Accuracy:  98.12  -Test_Accuracy  97.33  -time: 2146.08 \n",
      "Iteration:  8/10[==============] -Error: 0.0009395432  -Training_Accuracy:  98.26  -Test_Accuracy  97.29  -time: 2439.46 \n",
      "Iteration:  9/10[==============] -Error: 0.0009583825  -Training_Accuracy:  98.38  -Test_Accuracy  97.44  -time: 2931.78 \n",
      "Iteration: 10/10[==============] -Error: 0.0009196999  -Training_Accuracy:  98.63  -Test_Accuracy  97.27  -time: 3261.51 \n"
     ]
    }
   ],
   "source": [
    "#hidden = 300\n",
    "\n",
    "#create the network\n",
    "from NeuralNetwork import * \n",
    "mnist_net_300 = NeuralNetwork(784,300,10,iterations=10)\n",
    "\n",
    "#train the network\n",
    "mnist_net_300.train(training_data,validation_data, test_data)\n",
    "\n",
    "#save the model\n",
    "mnist_net_300.save(\"Models/model_9-iterations_50-learning_1-hidden_300-output_10.mdl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/figure2.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We notice that as we expected the test accuracy increases along with the number of neurons in the hidden layer because of the higher number of simultaneous functions that can be processed on the inputs. But the training of the networks take significantly more time because of these supplementary computations at each iteration, that's why I decided to limit the number of iterations to 10 for the 300 hidden neurons. Moreover, the testing accuracy doesn't improve much after 100 hidden neurons, probably because we reach the limit of computational complexity of one hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.5 : </b> Add one additionnal hidden layers and train your network, discuss your results with different setting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data .....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "training_data, validation_data, test_data=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Implementation (__init__, weights_initialisation, feedForward, backPropagate)\n",
    "    def __init__(self, input_layer_size, first_layer_size, second_layer_size, output_layer_size, iterations=50, learning_rate = 1, transfer_function = sigmoid):\n",
    "        \"\"\"\n",
    "        input: number of input neurons\n",
    "        first: number of hidden neurons in first hidden layer\n",
    "        second: number of hidden neurons in second hidden layer\n",
    "        output: number of output neurons\n",
    "        iterations: how many iterations\n",
    "        learning_rate: initial learning rate\n",
    "        transfer_function: explicit\n",
    "        dtransfer_function: derivative of transfer function\n",
    "        \"\"\"\n",
    "       \n",
    "        # initialize parameters\n",
    "        self.iterations = iterations   #iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.transfer_function = transfer_function\n",
    "        if (transfer_function == sigmoid):\n",
    "            self.dtransfer_function = dsigmoid\n",
    "        elif (transfer_function == tanh):\n",
    "            self.dtransfer_function = dtanh\n",
    "     \n",
    "        \n",
    "        # initialize arrays\n",
    "        self.input = input_layer_size+1  # +1 for the bias node in the input Layer\n",
    "        self.first = first_layer_size+1 #+1 for the bias node in the hidden layer \n",
    "        self.second = second_layer_size+1 #+1 for the bias node in the hidden layer \n",
    "        self.output = output_layer_size\n",
    "\n",
    "        # set up array of 1s for activations\n",
    "        self.a_input = np.ones(self.input)\n",
    "        self.a_first = np.ones(self.first)\n",
    "        self.a_second = np.ones(self.second)\n",
    "        self.a_out = np.ones(self.output)\n",
    "        \n",
    "        \n",
    "        #create randomized weights Yann Lecun method in 1988's paper ( Default values)\n",
    "        input_range = 1.0 / self.input ** (1/2)\n",
    "        self.W_input_to_first = np.random.normal(loc = 0, scale = input_range, size =(self.input, self.first-1))\n",
    "        self.W_first_to_second = np.random.uniform(size = (self.first, self.second-1)) / np.sqrt(self.first)\n",
    "        self.W_second_to_output = np.random.uniform(size = (self.second, self.output)) / np.sqrt(self.second)\n",
    "       \n",
    "        \n",
    "    def weights_initialisation(self,wi,wo):\n",
    "        self.W_input_to_first=wi # weights between input and first hidden layers\n",
    "        self.W_first_to_second=wh # weights between first hidden and second hidden layers\n",
    "        self.W_second_to_output=wo # weights between second hidden and output layers\n",
    "        \n",
    "    def feedForward(self, inputs):\n",
    "        \n",
    "        self.W_input_to_first = np.matrix(self.W_input_to_first)\n",
    "        self.W_first_to_second = np.matrix(self.W_first_to_second)\n",
    "        self.W_second_to_output = np.matrix(self.W_second_to_output)\n",
    "\n",
    "        inputs = np.append(inputs,[1])\n",
    "        self.a_input = np.matrix(inputs)\n",
    "        # Compute input activations\n",
    "        activation_input = self.a_input*self.W_input_to_first\n",
    "        \n",
    "        #Compute first hidden activations\n",
    "        output_first = self.transfer_function(activation_input)\n",
    "        output_first = np.concatenate((output_first,np.matrix([1])), axis=1)\n",
    "        self.a_first = output_first\n",
    "        activation_first = output_first*self.W_first_to_second\n",
    "        \n",
    "        #Compute second hidden activations\n",
    "        output_second = self.transfer_function(activation_first)\n",
    "        output_second = np.concatenate((output_second,np.matrix([1])), axis=1)\n",
    "        self.a_second = output_second\n",
    "        activation_second = output_second*self.W_second_to_output\n",
    "\n",
    "        \n",
    "        # Compute output activations\n",
    "        output_last = self.transfer_function(activation_second)\n",
    "        self.a_out = output_last\n",
    "        return(output_last)\n",
    "\n",
    "    def backPropagate(self, targets):\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        targets = np.matrix(targets)\n",
    "        error_last = self.a_out - targets\n",
    "        error_output = np.multiply(error_last,self.dtransfer_function(self.a_out))\n",
    "        # calculate error terms for second hidden\n",
    "        error_second = np.multiply((self.W_second_to_output*error_output.T).T,self.dtransfer_function(self.a_second))\n",
    "        error_second = np.matrix(np.array(error_second)[0][:-1])\n",
    "        # calculate error terms for first hidden\n",
    "        error_first = np.multiply((self.W_first_to_second*error_second.T).T,self.dtransfer_function(self.a_first))\n",
    "        error_first = np.matrix(np.array(error_first)[0][:-1])\n",
    "        \n",
    "        # update output weights\n",
    "        self.W_second_to_output=self.W_second_to_output-self.learning_rate*self.a_second.T*error_output\n",
    "        # update intermediate weights\n",
    "        self.W_first_to_second=self.W_first_to_second-self.learning_rate*self.a_first.T*error_second\n",
    "        # update input weights\n",
    "        self.W_input_to_first=self.W_input_to_first-self.learning_rate*self.a_input.T*error_first\n",
    "        # calculate error\n",
    "        error=0.5*np.dot(np.transpose(error_last),error_last)\n",
    "        return(np.array(error)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.0092435641  -Training_Accuracy:  90.19  -Test_Accuracy  90.93  -time: 55.61 \n",
      "Iteration:  2/50[==============] -Error: 0.0048046980  -Training_Accuracy:  90.30  -Test_Accuracy  91.00  -time: 110.16 \n",
      "Iteration:  3/50[==============] -Error: 0.0045486805  -Training_Accuracy:  92.23  -Test_Accuracy  92.57  -time: 160.19 \n",
      "Iteration:  4/50[==============] -Error: 0.0038884784  -Training_Accuracy:  93.21  -Test_Accuracy  93.13  -time: 208.20 \n",
      "Iteration:  5/50[==============] -Error: 0.0036440112  -Training_Accuracy:  93.95  -Test_Accuracy  94.05  -time: 256.48 \n",
      "Iteration:  6/50[==============] -Error: 0.0034928813  -Training_Accuracy:  93.20  -Test_Accuracy  93.22  -time: 302.03 \n",
      "Iteration:  7/50[==============] -Error: 0.0033296037  -Training_Accuracy:  93.65  -Test_Accuracy  93.55  -time: 346.48 \n",
      "Iteration:  8/50[==============] -Error: 0.0030511239  -Training_Accuracy:  94.33  -Test_Accuracy  94.68  -time: 390.93 \n",
      "Iteration:  9/50[==============] -Error: 0.0028027384  -Training_Accuracy:  94.08  -Test_Accuracy  93.83  -time: 434.15 \n",
      "Iteration: 10/50[==============] -Error: 0.0033107944  -Training_Accuracy:  94.28  -Test_Accuracy  94.02  -time: 479.21 \n",
      "Iteration: 11/50[==============] -Error: 0.0028592738  -Training_Accuracy:  93.57  -Test_Accuracy  93.61  -time: 523.62 \n",
      "Iteration: 12/50[==============] -Error: 0.0031672892  -Training_Accuracy:  93.56  -Test_Accuracy  93.73  -time: 569.20 \n",
      "Iteration: 13/50[==============] -Error: 0.0030033337  -Training_Accuracy:  94.70  -Test_Accuracy  94.58  -time: 612.83 \n",
      "Iteration: 14/50[==============] -Error: 0.0028662415  -Training_Accuracy:  94.67  -Test_Accuracy  94.19  -time: 656.60 \n",
      "Iteration: 15/50[==============] -Error: 0.0029238314  -Training_Accuracy:  94.53  -Test_Accuracy  94.17  -time: 700.17 \n",
      "Iteration: 16/50[==============] -Error: 0.0030368644  -Training_Accuracy:  94.31  -Test_Accuracy  94.16  -time: 744.99 \n",
      "Iteration: 17/50[==============] -Error: 0.0026996517  -Training_Accuracy:  94.93  -Test_Accuracy  94.55  -time: 789.59 \n",
      "Iteration: 18/50[==============] -Error: 0.0028352938  -Training_Accuracy:  94.63  -Test_Accuracy  94.40  -time: 834.85 \n",
      "Iteration: 19/50[==============] -Error: 0.0030193644  -Training_Accuracy:  94.95  -Test_Accuracy  94.64  -time: 880.93 \n",
      "Iteration: 20/50[==============] -Error: 0.0025445617  -Training_Accuracy:  94.51  -Test_Accuracy  94.08  -time: 929.05 \n",
      "Iteration: 21/50[==============] -Error: 0.0026748885  -Training_Accuracy:  95.35  -Test_Accuracy  94.98  -time: 974.22 \n",
      "Iteration: 22/50[==============] -Error: 0.0023321629  -Training_Accuracy:  95.11  -Test_Accuracy  94.75  -time: 1019.64 \n",
      "Iteration: 23/50[==============] -Error: 0.0024852952  -Training_Accuracy:  95.13  -Test_Accuracy  94.38  -time: 1063.16 \n",
      "Iteration: 24/50[==============] -Error: 0.0024213859  -Training_Accuracy:  95.55  -Test_Accuracy  94.96  -time: 1107.67 \n",
      "Iteration: 25/50[==============] -Error: 0.0024629821  -Training_Accuracy:  95.29  -Test_Accuracy  94.68  -time: 1152.09 \n",
      "Iteration: 26/50[==============] -Error: 0.0022380094  -Training_Accuracy:  95.57  -Test_Accuracy  95.22  -time: 1198.42 \n",
      "Iteration: 27/50[==============] -Error: 0.0024418978  -Training_Accuracy:  95.78  -Test_Accuracy  95.23  -time: 1243.90 \n",
      "Iteration: 28/50[==============] -Error: 0.0022471415  -Training_Accuracy:  95.62  -Test_Accuracy  95.25  -time: 1293.44 \n",
      "Iteration: 29/50[==============] -Error: 0.0024944568  -Training_Accuracy:  95.26  -Test_Accuracy  95.07  -time: 1341.09 \n",
      "Iteration: 30/50[==============] -Error: 0.0024149242  -Training_Accuracy:  95.51  -Test_Accuracy  94.86  -time: 1386.96 \n",
      "Iteration: 31/50[==============] -Error: 0.0023419380  -Training_Accuracy:  95.64  -Test_Accuracy  94.91  -time: 1434.16 \n",
      "Iteration: 32/50[==============] -Error: 0.0026146316  -Training_Accuracy:  94.26  -Test_Accuracy  93.53  -time: 1480.65 \n",
      "Iteration: 33/50[==============] -Error: 0.0028563812  -Training_Accuracy:  95.45  -Test_Accuracy  94.62  -time: 1527.50 \n",
      "Iteration: 34/50[==============] -Error: 0.0023468313  -Training_Accuracy:  95.29  -Test_Accuracy  94.63  -time: 1575.43 \n",
      "Iteration: 35/50[==============] -Error: 0.0023505497  -Training_Accuracy:  96.16  -Test_Accuracy  95.26  -time: 1623.56 \n",
      "Iteration: 36/50[==============] -Error: 0.0021647049  -Training_Accuracy:  95.98  -Test_Accuracy  95.22  -time: 1668.81 \n",
      "Iteration: 37/50[==============] -Error: 0.0021610705  -Training_Accuracy:  95.88  -Test_Accuracy  95.02  -time: 1712.76 \n",
      "Iteration: 38/50[==============] -Error: 0.0024884434  -Training_Accuracy:  95.45  -Test_Accuracy  95.04  -time: 1758.12 \n",
      "Iteration: 39/50[==============] -Error: 0.0023513015  -Training_Accuracy:  95.43  -Test_Accuracy  94.76  -time: 1803.91 \n",
      "Iteration: 40/50[==============] -Error: 0.0024732963  -Training_Accuracy:  95.94  -Test_Accuracy  95.31  -time: 1849.61 \n",
      "Iteration: 41/50[==============] -Error: 0.0022128670  -Training_Accuracy:  95.74  -Test_Accuracy  94.73  -time: 1894.91 \n",
      "Iteration: 42/50[==============] -Error: 0.0024753010  -Training_Accuracy:  95.78  -Test_Accuracy  95.23  -time: 1939.12 \n",
      "Iteration: 43/50[==============] -Error: 0.0028223488  -Training_Accuracy:  95.59  -Test_Accuracy  95.22  -time: 1982.86 \n",
      "Iteration: 44/50[==============] -Error: 0.0025102632  -Training_Accuracy:  96.06  -Test_Accuracy  95.27  -time: 2028.91 \n",
      "Iteration: 45/50[==============] -Error: 0.0023269119  -Training_Accuracy:  96.19  -Test_Accuracy  95.35  -time: 2073.76 \n",
      "Iteration: 46/50[==============] -Error: 0.0022534730  -Training_Accuracy:  95.66  -Test_Accuracy  94.85  -time: 2120.11 \n",
      "Iteration: 47/50[==============] -Error: 0.0023506591  -Training_Accuracy:  96.06  -Test_Accuracy  95.26  -time: 2166.21 \n",
      "Iteration: 48/50[==============] -Error: 0.0025701489  -Training_Accuracy:  96.07  -Test_Accuracy  95.17  -time: 2213.31 \n",
      "Iteration: 49/50[==============] -Error: 0.0021763162  -Training_Accuracy:  95.87  -Test_Accuracy  95.04  -time: 2259.39 \n",
      "Iteration: 50/50[==============] -Error: 0.0021143076  -Training_Accuracy:  95.91  -Test_Accuracy  95.23  -time: 2303.84 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "from DeepNeuralNetwork import *\n",
    "\n",
    "mnist_dnet = DeepNeuralNetwork(784,30,30,10)\n",
    "\n",
    "mnist_dnet.train(training_data,validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Figures/model10.png\", width=\"700\" height=\"900\"> \n",
    "<img src=\"Figures/model10_1.png\", width=\"700\" height=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We notice the same curve aspect as with one layer of 30 neurons. The results are also pretty close, even though with the ratio training time / total number of neurons this one is a little bit faster than all of the one layer networks.\n",
    "\n",
    "Adding one layer is useful when we need to model more complex functions (one layer: half planes vs. two layers: convex regions). What we can deduce from these results is that we clearly don't need to get convex regions to distinguish numbers, half planes are enough. The training time performance is the only thing that improves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
